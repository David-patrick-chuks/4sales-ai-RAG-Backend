import { scrapeAllRoutes } from '../src/utils/scrapeWebsite.ts';

async function testWebsiteScraping() {
  console.log('ğŸ§ª Testing Website Scraping Functionality');
  console.log('==========================================');

  // Test URLs - you can change these to test different websites
  const testUrls = [
    'https://davidtsx.vercel.app',
  ];

  for (const url of testUrls) {
    console.log(`\nğŸ“„ Testing URL: ${url}`);
    console.log('â”€'.repeat(50));

    try {
      // Test first route only (fast mode)
      console.log('â±ï¸  Testing first route only mode...');
      const startTime = Date.now();
      
      const result = await scrapeAllRoutes(url, { firstRouteOnly: true });
      const endTime = Date.now();
      const duration = endTime - startTime;

      if (typeof result === 'string') {
        console.log('âœ… Success! Content scraped:');
        console.log(`ğŸ“Š Duration: ${duration}ms`);
        console.log(`ğŸ“ Content length: ${result.length} characters`);
        console.log(`ğŸ“ First 200 characters: ${result.substring(0, 200)}...`);
        
        // Show a sample of the cleaned content
        const lines = result.split('\n').filter(line => line.trim().length > 0);
        console.log(`ğŸ“„ Number of text lines: ${lines.length}`);
        if (lines.length > 0) {
          console.log(`ğŸ“– Sample line: "${lines[0].substring(0, 100)}..."`);
        }
      } else {
        console.log('âŒ Error occurred:');
        console.log(`ğŸ” Error: ${result.error}`);
        console.log(`ğŸ“Š Duration: ${duration}ms`);
      }

    } catch (error) {
      console.log('âŒ Exception occurred:');
      console.log(`ğŸ” Error: ${error.message}`);
    }
  }

  console.log('\nğŸ¯ Test Summary');
  console.log('===============');
  console.log('âœ… First route only mode is working for faster testing');
  console.log('ğŸ’¡ You can now test website scraping without waiting for full crawl');
  console.log('ğŸ”§ To test full crawling, remove the { firstRouteOnly: true } option');
}

// Run the test
testWebsiteScraping().catch(console.error); 